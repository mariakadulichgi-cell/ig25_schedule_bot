import os
import re
import csv
import io
import time
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import requests
from dotenv import load_dotenv

from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes, MessageHandler, filters


# ----------------- –ù–ê–°–¢–†–û–ô–ö–ò -----------------
TZ = ZoneInfo("Asia/Krasnoyarsk")  # –ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫ (+07)
DEFAULT_GROUP = os.getenv("GROUP_NAME", "–ò–ì25-01–ë-–û–ú")

DATE_RE = re.compile(r"\b(\d{1,2})[.\-/](\d{1,2})(?:[.\-/](\d{2,4}))?\b")  # 02.02 –∏–ª–∏ 02.02.26
TIME_RE = re.compile(r"(\d{1,2})[.:](\d{2})\s*[-‚Äì‚Äî]\s*(\d{1,2})[.:](\d{2})")  # 8:30-10:05 –∏ —Ç.–ø.

# –∫—ç—à CSV —á—Ç–æ–±—ã –Ω–µ –¥–æ–ª–±–∏—Ç—å –≥—É–≥–ª –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
_CACHE_TEXT = None
_CACHE_TS = 0
CACHE_SECONDS = 60


def norm(s: str) -> str:
    return (s or "").replace("\xa0", " ").strip()


def norm_group(s: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã: —Ä–∞–∑–Ω—ã–µ —Ç–∏—Ä–µ/–ø—Ä–æ–±–µ–ª—ã -> –æ–¥–∏–Ω–∞–∫–æ–≤–æ"""
    s = norm(s)
    s = s.replace("‚Äî", "-").replace("‚Äì", "-")
    s = re.sub(r"\s+", "", s)
    return s.upper()


def normalize_time(s: str) -> str:
    s = norm(s)
    m = TIME_RE.search(s)
    if not m:
        return s
    h1, m1, h2, m2 = m.groups()
    return f"{int(h1)}:{m1}‚Äì{int(h2)}:{m2}"


def parse_ddmm(text: str) -> str | None:
    m = DATE_RE.search(text or "")
    if not m:
        return None
    dd = int(m.group(1))
    mm = int(m.group(2))
    return f"{dd:02d}.{mm:02d}"


def fetch_csv_text(url: str) -> str:
    global _CACHE_TEXT, _CACHE_TS
    now = time.time()
    if _CACHE_TEXT and (now - _CACHE_TS) < CACHE_SECONDS:
        return _CACHE_TEXT

    r = requests.get(url, timeout=25)
    r.raise_for_status()
    _CACHE_TEXT = r.text
    _CACHE_TS = now
    return r.text


def find_header_and_group_cols(rows: list[list[str]], group_name: str):
    """
    –ò—â–µ–º —Å—Ç—Ä–æ–∫—É, –≥–¥–µ –µ—Å—Ç—å '–î–∞—Ç–∞' –∏ '–ß–∞—Å—ã' (–≤ –ø–µ—Ä–≤—ã—Ö 60 —Å—Ç—Ä–æ–∫–∞—Ö),
    –ø–æ—Ç–æ–º –Ω–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏ –≥—Ä—É–ø–ø—ã –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö.
    """
    g_need = norm_group(group_name)

    header_row_i = None
    date_col = None
    time_col = None

    # 1) —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: –∏—â–µ–º "–¥–∞—Ç–∞" –∏ "—á–∞—Å—ã"
    for i in range(min(60, len(rows))):
        row = [norm(x) for x in rows[i]]
        low = [x.lower() for x in row]
        if "–¥–∞—Ç–∞" in low and "—á–∞—Å—ã" in low:
            header_row_i = i
            date_col = low.index("–¥–∞—Ç–∞")
            time_col = low.index("—á–∞—Å—ã")
            break

    if header_row_i is None:
        raise RuntimeError("–ù–µ –Ω–∞—à–ª–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏ '–î–∞—Ç–∞' –∏ '–ß–∞—Å—ã' –≤ —Ç–∞–±–ª–∏—Ü–µ (CSV).")

    # 2) –∫–æ–ª–æ–Ω–∫–∏ –≥—Ä—É–ø–ø—ã: –∏—â–µ–º —Ä—è–¥–æ–º –Ω–∏–∂–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 12 —Å—Ç—Ä–æ–∫)
    group_cols = []
    for i in range(header_row_i, min(header_row_i + 12, len(rows))):
        row = rows[i]
        for j, cell in enumerate(row):
            if norm_group(cell) == g_need:
                group_cols.append(j)

    group_cols = sorted(set(group_cols))
    return header_row_i, date_col, time_col, group_cols


def extract_schedule_for_date(csv_text: str, group_name: str, target_ddmm: str):
    reader = csv.reader(io.StringIO(csv_text))
    rows = list(reader)

    header_i, date_col, time_col, group_cols = find_header_and_group_cols(rows, group_name)

    if not group_cols:
        # –ø–æ–ª–µ–∑–Ω—ã–π –¥–µ–±–∞–≥: –∫–∞–∫–∏–µ –≥—Ä—É–ø–ø—ã –≤–∏–¥–∏–º –≤ —Ç–∞–±–ª–∏—Ü–µ
        groups_found = set()
        for i in range(min(40, len(rows))):
            for cell in rows[i]:
                c = norm(cell)
                if c.startswith("–ò–ì"):
                    groups_found.add(c)
        hint = ", ".join(sorted(groups_found)) if groups_found else "–Ω–µ –Ω–∞—à–ª–∞ –Ω–∏ –æ–¥–Ω–æ–π"
        raise RuntimeError(f"–ù–µ –Ω–∞—à–ª–∞ –∫–æ–ª–æ–Ω–∫—É –≥—Ä—É–ø–ø—ã '{group_name}'. –í —Ç–∞–±–ª–∏—Ü–µ –≤–∏–∂—É –≥—Ä—É–ø–ø—ã: {hint}")

    cur_date = ""
    cur_time = ""
    items = []

    for r in rows[header_i + 1 :]:
        # –∑–∞—â–∏—Ç–∞: —Ä–∞—Å—à–∏—Ä—è–µ–º —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∞—è
        need_len = max(date_col, time_col, max(group_cols)) + 1
        if len(r) < need_len:
            r = r + [""] * (need_len - len(r))

        d_raw = norm(r[date_col])
        t_raw = norm(r[time_col])

        ddmm = parse_ddmm(d_raw)
        if ddmm:
            cur_date = ddmm

        t_norm = normalize_time(t_raw)
        if TIME_RE.search(t_raw):
            cur_time = t_norm

        if cur_date != target_ddmm:
            continue

        # —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≥—Ä—É–ø–ø—ã
        parts = []
        for j in group_cols:
            v = norm(r[j])
            if not v:
                continue
            # —á–∏—Å—Ç–∏–º –º—É—Å–æ—Ä
            if "—Å–µ–º–µ—Å—Ç—Ä" in v.lower() or "—É—Ç–≤–µ—Ä–∂–¥–∞—é" in v.lower():
                continue
            parts.append(v)

        if not parts:
            continue

        # –æ–±—ä–µ–¥–∏–Ω—è–µ–º, —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ —è—á–µ–π–∫–∏
        cell_text = "\n".join(parts).strip()
        lines = [x.strip() for x in cell_text.splitlines() if x.strip()]
        uniq_lines = []
        seen = set()
        for x in lines:
            if x not in seen:
                seen.add(x)
                uniq_lines.append(x)

        items.append((cur_time, "\n".join(uniq_lines)))

    # —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã –ø–æ (–≤—Ä–µ–º—è + —Ç–µ–∫—Å—Ç)
    out = []
    seen = set()
    for tm, tx in items:
        key = (tm, tx)
        if key in seen:
            continue
        seen.add(key)
        out.append((tm, tx))
    return out

from collections import OrderedDict

def merge_items_by_time(items: list[tuple[str, str]]) -> list[tuple[str, str]]:
    merged: "OrderedDict[str, list[str]]" = OrderedDict()

    for tm, tx in items:
        tm = (tm or "").strip()
        tx = (tx or "").strip()
        if not tm or not tx:
            continue

        # —Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ —á–∏—Å—Ç–∏–º
        lines = [l.strip() for l in tx.splitlines() if l.strip()]

        bucket = merged.setdefault(tm, [])
        for l in lines:
            # —É–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ "‚Ä¢" –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ–ø–∞–ª–∏
            l = l.lstrip("‚Ä¢").strip()
            if l and l not in bucket:
                bucket.append(l)

    # —Å–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
    out = []
    for tm, lines in merged.items():
        out.append((tm, "\n".join(lines)))
    return out


def _fix_parts(parts: list[str]) -> list[str]:
    # 1) —á–∏—Å—Ç–∏–º –∏ —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
    parts = [p.strip() for p in parts if p and p.strip()]

    # 2) —Å–∫–ª–µ–∏–≤–∞–µ–º "–ø—Ä" + —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ (–µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "/")
    out = []
    i = 0
    while i < len(parts):
        p = parts[i]
        low = p.lower()

        if low in {"–ø—Ä", "–ø—Ä."} and i + 1 < len(parts):
            nxt = parts[i + 1].strip()
            if nxt.startswith("/"):   # –±—ã–ª–æ "–ø—Ä" –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ, "/ 3-17" –Ω–∞ –¥—Ä—É–≥–æ–π
                out.append(f"–ø—Ä {nxt}")
                i += 2
                continue

        out.append(p)
        i += 1

    # 3) –ø—Ä–∏–∫–ª–µ–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É "–ø—Ä ..." –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π (–µ—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –ø–æ—Ö–æ–∂–∞ –Ω–∞ –∞–¥—Ä–µ—Å/–∞—É–¥–∏—Ç–æ—Ä–∏—é)
    def should_attach(prev: str) -> bool:
        s = prev.lower()
        return any(k in s for k in ("–º—Ñ–∫", "–ø—Ä.", "—Å—Ç—Ä", "–∞—É–¥", "—Å–∏–Ω—Ö—Ä–æ–Ω", "—É–ª.", "–∫–æ—Ä–ø"))

    final = []
    for p in out:
        if final and p.lower().startswith("–ø—Ä") and should_attach(final[-1]):
            final[-1] = f"{final[-1]} {p}"
        else:
            final.append(p)

    return final


def _compact_spaces(s: str) -> str:
    # —É–±–∏—Ä–∞–µ–º —Ç–∞–±—ã/–Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∂–∏–º–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    s = (s or "").replace("\u00a0", " ").replace("\t", " ")
    s = re.sub(r"[ ]{2,}", " ", s)
    return s.strip()

def _glue_pr_lines(lines: list[str]) -> list[str]:
    """
    –°–∫–ª–µ–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ "–ø—Ä", "–ø—Ä / 3-17", "/ 3-17"
    —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ —É–µ–∑–∂–∞–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
    """
    out: list[str] = []
    for raw in lines:
        ln = _compact_spaces(raw)
        if not ln:
            continue

        low = ln.lower()

        # –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "–ø—Ä" –∏–ª–∏ "/" ‚Äî –¥–æ–∫–ª–µ–∏–≤–∞–µ–º –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        if out and (low == "–ø—Ä" or low.startswith("–ø—Ä/") or low.startswith("–ø—Ä /") or ln.startswith("/")):
            out[-1] = _compact_spaces(out[-1] + " " + ln)
            continue

        out.append(ln)

    return out

def format_schedule(group_name: str, ddmm: str, items: list[tuple[str, str]]) -> str:
    title = f"{group_name} ‚Äî {ddmm}:"
    if not items:
        return title + "\n‚Ä¢ –ù–µ—Ç –∑–∞–Ω—è—Ç–∏–π / –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

    items = merge_items_by_time(items)

    out_lines = [title]
    for tm, tx in items:
        tx = (tx or "").replace("\r", "")
        raw_lines = tx.splitlines()
        parts = _glue_pr_lines(raw_lines)

        if not parts:
            continue

        # –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —Å –≤—Ä–µ–º–µ–Ω–µ–º
        out_lines.append(f"‚Ä¢ {tm} ‚Äî {parts[0]}")

        # –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ —Å –æ—Ç—Å—Ç—É–ø–æ–º (–±–µ–∑ —Å—Ç—Ä–µ–ª–æ–∫)
        for p in parts[1:]:
            out_lines.append(f"  {p}")

        # –ü–£–°–¢–ê–Ø –°–¢–†–û–ö–ê –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏ (–∫–∞–∫ ‚Äú–∞–±–∑–∞—Ü‚Äù)
        out_lines.append("")

    # —É–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ª–∏—à–Ω–µ–≥–æ —Ö–≤–æ—Å—Ç–∞
    while out_lines and out_lines[-1] == "":
        out_lines.pop()

    return "\n".join(out_lines)




# ----------------- TELEGRAM HANDLERS -----------------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –û–¢–ï–õ–¨–ö–ê ü©µ. –î–∞–≤–∞–π –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º! –ö–æ–º–∞–Ω–¥—ã:\n"
        "/day 30.01 ‚Äî —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç—É (–î–î.–ú–ú)\n"
        "–ú–æ–∂–Ω–æ –∏ —Ç–µ–∫—Å—Ç–æ–º: –¥–µ–Ω—å 30.01"
    )


async def cmd_day(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = context.args
    if args:
        ddmm = parse_ddmm(" ".join(args))
        if not ddmm:
            await update.message.reply_text("–§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: /day 30.01 (–î–î.–ú–ú)")
            return
    else:
        ddmm = datetime.now(TZ).strftime("%d.%m")

    await send_schedule(update, ddmm)


async def text_day(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip().lower()
    m = re.match(r"^(?:–¥–µ–Ω—å\s+)?(\d{1,2}[.\-/]\d{1,2}(?:[.\-/]\d{2,4})?)$", text)
    if not m:
        return
    ddmm = parse_ddmm(m.group(1))
    if not ddmm:
        return
    await send_schedule(update, ddmm)


async def send_schedule(update: Update, ddmm: str):
    url = os.getenv("SHEET_CSV_URL", "").strip()
    group = os.getenv("GROUP_NAME", DEFAULT_GROUP).strip()

    if not url:
        await update.message.reply_text("–ù–µ –∑–∞–¥–∞–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è SHEET_CSV_URL.")
        return

    try:
        csv_text = fetch_csv_text(url)
        items = extract_schedule_for_date(csv_text, group, ddmm)
        msg = format_schedule(group, ddmm, items)
        await update.message.reply_text(msg)
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {e}")


def main():
    load_dotenv()  # —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω –≤ .env

    token = os.getenv("BOT_TOKEN", "").strip()
    if not token:
        raise RuntimeError("–ù–µ—Ç BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env –∏–ª–∏ export).")

    app = Application.builder().token(token).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("day", cmd_day))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_day))

    print("Bot started / polling")
    app.run_polling()


if __name__ == "__main__":
    main()

