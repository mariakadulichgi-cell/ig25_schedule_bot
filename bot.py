import os
import re
import csv
import io
import time
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import requests
from dotenv import load_dotenv

from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    filters,
)

# =========================
# Render + Flask (keep alive)
# =========================
from threading import Thread
from flask import Flask

web = Flask(__name__)

@web.get("/")
def home():
    return "ok", 200

def run_web():
    port = int(os.environ.get("PORT", "10000"))
    web.run(host="0.0.0.0", port=port)

def keep_alive():
    Thread(target=run_web, daemon=True).start()


# =========================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# =========================
TZ = ZoneInfo("Asia/Krasnoyarsk")  # –ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫ (+07)
DEFAULT_GROUP = os.getenv("GROUP_NAME", "–ò–ì25-01–ë-–û–ú")

# –î–∞—Ç—ã —Ç–∏–ø–∞: 02.02 / 02-02 / 02/02 / 02.02.26
DATE_RE = re.compile(r"\b(\d{1,2})[.\-/](\d{1,2})(?:[.\-/]\d{2,4})?\b")

# –í—Ä–µ–º—è: 8:30-10:05 / 08:30‚Äì10:05 / 8.30-10.05
TIME_RE = re.compile(r"(\d{1,2})[.:](\d{2})\s*[‚Äì‚Äî-]\s*(\d{1,2})[.:](\d{2})")

# –ö—ç—à, —á—Ç–æ–±—ã –Ω–µ –¥—ë—Ä–≥–∞—Ç—å –≥—É–≥–ª –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
_CACHE_TEXT = None
_CACHE_TS = 0
CACHE_SECONDS = 60


# =========================
# –£—Ç–∏–ª–∏—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
# =========================
def norm(s: str) -> str:
    return (s or "").replace("\xa0", " ").strip()

def norm_group(s: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã: —Ä–∞–∑–Ω—ã–µ —Ç–∏—Ä–µ/–ø—Ä–æ–±–µ–ª—ã -> –æ–¥–∏–Ω–∞–∫–æ–≤–æ"""
    s = norm(s)
    s = s.replace("‚Äî", "-").replace("‚Äì", "-")
    s = re.sub(r"\s+", " ", s)
    return s.upper()

def parse_ddmm(text: str) -> str | None:
    m = DATE_RE.search(text or "")
    if not m:
        return None
    dd = int(m.group(1))
    mm = int(m.group(2))
    return f"{dd:02d}.{mm:02d}"

def normalize_time(text: str) -> str | None:
    """–ò—â–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ HH:MM‚ÄìHH:MM"""
    m = TIME_RE.search(text or "")
    if not m:
        return None
    h1, m1, h2, m2 = m.groups()
    return f"{int(h1):02d}:{m1}‚Äì{int(h2):02d}:{m2}"

def fetch_csv_text(url: str) -> str:
    global _CACHE_TEXT, _CACHE_TS
    now = time.time()
    if _CACHE_TEXT and (now - _CACHE_TS) < CACHE_SECONDS:
        return _CACHE_TEXT

    r = requests.get(url, timeout=25)
    r.raise_for_status()
    _CACHE_TEXT = r.text
    _CACHE_TS = now
    return _CACHE_TEXT

def read_csv_rows(csv_text: str) -> list[list[str]]:
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV (Google —á–∞—Å—Ç–æ –¥–∞—ë—Ç ;)
    sample = csv_text[:5000]
    delim = ";" if sample.count(";") > sample.count(",") else ","

    reader = csv.reader(io.StringIO(csv_text), delimiter=delim)
    return list(reader)

# =========================
# –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–æ–ª–æ–Ω–æ–∫ –≥—Ä—É–ø–ø—ã
# =========================
def find_header_and_group_cols(rows: list[list[str]], group_name: str):
    """
    –ò—â–µ–º —Å—Ç—Ä–æ–∫—É, –≥–¥–µ –µ—Å—Ç—å '–î–∞—Ç–∞' –∏ '–ß–∞—Å—ã' (–≤ –ø–µ—Ä–≤—ã—Ö 80 —Å—Ç—Ä–æ–∫–∞—Ö),
    –∑–∞—Ç–µ–º –∏—â–µ–º –∫–æ–ª–æ–Ω–∫—É –≥—Ä—É–ø–ø—ã —Ä—è–¥–æ–º –Ω–∏–∂–µ.
    """
    g_need = norm_group(group_name)

    header_row_i = None
    date_col = None
    time_col = None

    # 1) —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    for i in range(min(80, len(rows))):
        row = [norm(x) for x in rows[i]]
        low = [x.lower() for x in row]

        # –∏—â–µ–º –ø–æ "–≤—Ö–æ–∂–¥–µ–Ω–∏—é", –∞ –Ω–µ –ø–æ —Å—Ç—Ä–æ–≥–æ–º—É —Ä–∞–≤–µ–Ω—Å—Ç–≤—É
        def find_col(keyword: str):
            for idx, cell in enumerate(low):
                if keyword in cell:
                    return idx
            return None

        dc = find_col("–¥–∞—Ç–∞")
        tc = find_col("—á–∞—Å—ã")
        if dc is not None and tc is not None:
            header_row_i = i
            date_col = dc
            time_col = tc
            break

    if header_row_i is None:
        # –¥–µ–±–∞–≥: –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        preview = "\n".join([" | ".join([norm(x) for x in rows[k][:8]]) for k in range(min(8, len(rows)))])
        raise RuntimeError("–ù–µ –Ω–∞—à–ª–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏ '–î–∞—Ç–∞' –∏ '–ß–∞—Å—ã' –≤ —Ç–∞–±–ª–∏—Ü–µ (CSV).\n–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:\n" + preview)

    # 2) –∫–æ–ª–æ–Ω–∫–∏ –≥—Ä—É–ø–ø—ã ‚Äî –∏—â–µ–º –Ω–∏–∂–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 20 —Å—Ç—Ä–æ–∫)
    group_cols = []
    for i in range(header_row_i, min(header_row_i + 20, len(rows))):
        row = rows[i]
        for j, cell in enumerate(row):
            if norm_group(cell) == g_need:
                group_cols.append(j)

    group_cols = sorted(set(group_cols))
    return header_row_i, date_col, time_col, group_cols


# =========================
# –°–∫–ª–µ–π–∫–∏ "–ø—Ä/–ª–µ–∫/–ª–∞–±" –∏ —á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫
# =========================
def compact_spaces(s: str) -> str:
    s = (s or "").replace("\xa0", " ").replace("\t", " ")
    s = re.sub(r"[ ]{2,}", " ", s)
    return s.strip()

def glue_markers_to_prev(lines: list[str]) -> list[str]:
    """
    –ü—Ä–∏–∫–ª–µ–∏–≤–∞–µ–º '–ø—Ä', '–ª–µ–∫', '–ª–∞–±' –∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ä–æ–¥–µ '–ø—Ä / 3-17' –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–µ.
    –ü—Ä–∏–º–µ—Ä:
      "... —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ,"  + "–ø—Ä" + "/ 3-17"  -> "... —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –ø—Ä / 3-17"
    """
    out: list[str] = []
    for raw in lines:
        ln = compact_spaces(raw)
        if not ln:
            continue

        low = ln.lower()

        is_marker_alone = low in {"–ø—Ä", "–ª–µ–∫", "–ª–∞–±", "—Å–µ–º"}  # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ–ø–∞–¥–∞–µ—Ç—Å—è
        is_marker_start = bool(re.match(r"^(–ø—Ä|–ª–µ–∫|–ª–∞–±)\b", low))
        is_slash_room = ln.startswith("/")  # "/ 3-17" —Ç–æ–∂–µ –ø—Ä–∏–∫–ª–µ–∏–º

        if out and (is_marker_alone or is_marker_start or is_slash_room):
            out[-1] = compact_spaces(out[-1] + " " + ln)
        else:
            out.append(ln)

    return out


# =========================
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –¥–∞—Ç—É
# =========================
def extract_schedule_for_date(csv_text: str, group_name: str, target_ddmm: str):
    rows = read_csv_rows(csv_text)

    header_i, date_col, time_col, group_cols = find_header_and_group_cols(rows, group_name)

    if not group_cols:
        # –¥–µ–±–∞–≥ ‚Äî –∫–∞–∫–∏–µ –≥—Ä—É–ø–ø—ã –≤–∏–¥–∏–º
        groups_found = set()
        for i in range(min(40, len(rows))):
            for cell in rows[i]:
                c = norm(cell)
                if c.upper().startswith("–ò–ì"):
                    groups_found.add(c)
        hint = ", ".join(sorted(groups_found)) if groups_found else "–Ω–µ –Ω–∞—à–ª–∞ –Ω–∏ –æ–¥–Ω–æ–π"
        raise RuntimeError(f"–ù–µ –Ω–∞—à–ª–∞ –∫–æ–ª–æ–Ω–∫—É –≥—Ä—É–ø–ø—ã '{group_name}'. –í —Ç–∞–±–ª–∏—Ü–µ –≤–∏–∂—É –≥—Ä—É–ø–ø—ã: {hint}")

    cur_date = None
    cur_time = None
    items: list[tuple[str, str]] = []

    for r in rows[header_i + 1:]:
        # –∑–∞—â–∏—Ç–∞: —Ä–∞—Å—à–∏—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        need_len = max(date_col, time_col, max(group_cols)) + 1
        if len(r) < need_len:
            r = r + [""] * (need_len - len(r))

        d_raw = norm(r[date_col])
        t_raw = norm(r[time_col])

        ddmm = parse_ddmm(d_raw)
        if ddmm:
            cur_date = ddmm

        t_norm = normalize_time(t_raw)
        if t_norm:
            cur_time = t_norm

        if cur_date != target_ddmm:
            continue

        # —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ –≥—Ä—É–ø–ø—ã
        parts = []
        for j in group_cols:
            v = norm(r[j])
            if not v:
                continue

            # —á–∏—Å—Ç–∏–º –º—É—Å–æ—Ä–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (–ø–æ–¥ —Å–µ–±—è –º–æ–∂–µ—à—å —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
            lv = v.lower()
            if "—Å–µ–º–µ—Å—Ç—Ä" in lv or "—É—Ç–≤–µ—Ä–∂–¥–∞—é" in lv:
                continue

            parts.append(v)

        if not parts:
            continue

        cell_text = "\n".join(parts).strip()
        lines = [x.strip() for x in cell_text.splitlines() if x.strip()]

        # –°–∫–ª–µ–π–∫–∏ –ø—Ä/–ª–µ–∫/–ª–∞–± –∏ "/ 3-17" –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        lines = glue_markers_to_prev(lines)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ —Å—Ç—Ä–æ–∫ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π –ø–∞—Ä—ã
        uniq = []
        seen = set()
        for x in lines:
            if x not in seen:
                seen.add(x)
                uniq.append(x)

        text_block = "\n".join(uniq).strip()
        if cur_time and text_block:
            items.append((cur_time, text_block))

    return items


# =========================
# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä –≤—Ä–µ–º–µ–Ω–∏)
# =========================
def merge_items_by_time(items: list[tuple[str, str]]) -> list[tuple[str, str]]:
    """
    –ï—Å–ª–∏ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –≤—Ä–µ–º—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç—ã –≤ –æ–¥–∏–Ω –±–ª–æ–∫.
    """
    merged: dict[str, list[str]] = {}
    for tm, tx in items:
        tm = (tm or "").strip()
        tx = (tx or "").strip()
        if not tm or not tx:
            continue
        merged.setdefault(tm, []).append(tx)

    out: list[tuple[str, str]] = []
    for tm in sorted(merged.keys()):
        # –°–∫–ª–µ–∏–º –±–ª–æ–∫–∏, —É–±–µ—Ä—ë–º –¥—É–±–ª—å –±–ª–æ–∫–æ–≤
        blocks = []
        seen = set()
        for b in merged[tm]:
            if b not in seen:
                seen.add(b)
                blocks.append(b)
        out.append((tm, "\n".join(blocks)))
    return out


# =========================
# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
# =========================
def format_schedule(group_name: str, ddmm: str, items: list[tuple[str, str]]) -> str:
    title = f"{group_name} ‚Äî {ddmm}:"
    if not items:
        return title + "\n‚Ä¢ –ù–µ—Ç –ø–∞—Ä—ã"

    items = merge_items_by_time(items)

    out_lines = [title]
    for tm, tx in items:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∞—Ä—ã: –≤—Ä–µ–º—è + –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –±–ª–æ–∫–∞
        raw_lines = [x.strip() for x in (tx or "").splitlines() if x.strip()]
        if not raw_lines:
            continue

        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –µ—â—ë —Ä–∞–∑ —Å–∫–ª–µ–∏–º –º–∞—Ä–∫–µ—Ä—ã
        raw_lines = glue_markers_to_prev(raw_lines)

        first = raw_lines[0]
        out_lines.append(f"‚Ä¢ {tm} ‚Äî {first}")

        # –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ —Å –æ—Ç—Å—Ç—É–ø–æ–º
        for ln in raw_lines[1:]:
            out_lines.append(f"  {ln}")

        out_lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏

    # —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç–æ–≤—É—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    while out_lines and out_lines[-1] == "":
        out_lines.pop()

    return "\n".join(out_lines)


# =========================
# Telegram handlers
# =========================
async def send_schedule(update: Update, ddmm: str):
    url = os.getenv("SHEET_CSV_URL", "").strip()
    group = os.getenv("GROUP_NAME", DEFAULT_GROUP).strip()

    if not url:
        await update.message.reply_text("–ù–µ –∑–∞–¥–∞–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è SHEET_CSV_URL.")
        return

    try:
        csv_text = fetch_csv_text(url)
        items = extract_schedule_for_date(csv_text, group, ddmm)
        msg = format_schedule(group, ddmm, items)
        await update.message.reply_text(msg)
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {e}")


async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –û–¢–ï–õ–¨–ö–ê üíô\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/today ‚Äî —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è\n"
        "/tomorrow ‚Äî —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –∑–∞–≤—Ç—Ä–∞\n"
        "/day 30.01 ‚Äî —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç—É (–î–î.–ú–ú)\n\n"
        "–ú–æ–∂–Ω–æ –∏ —Ç–µ–∫—Å—Ç–æ–º: 30.01 –∏–ª–∏ ¬´–¥–µ–Ω—å 30.01¬ª"
    )

async def cmd_today(update: Update, context: ContextTypes.DEFAULT_TYPE):
    ddmm = datetime.now(TZ).strftime("%d.%m")
    await send_schedule(update, ddmm)

async def cmd_tomorrow(update: Update, context: ContextTypes.DEFAULT_TYPE):
    ddmm = (datetime.now(TZ) + timedelta(days=1)).strftime("%d.%m")
    await send_schedule(update, ddmm)

async def cmd_day(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = context.args
    if args:
        ddmm = parse_ddmm(" ".join(args))
        if not ddmm:
            await update.message.reply_text("–§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: /day 30.01 (–î–î.–ú–ú)")
            return
    else:
        ddmm = datetime.now(TZ).strftime("%d.%m")

    await send_schedule(update, ddmm)

async def text_day(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip().lower()

    # –ø—Ä–∏–Ω–∏–º–∞–µ—Ç "30.01" –∏–ª–∏ "–¥–µ–Ω—å 30.01"
    m = re.match(r"^(?:–¥–µ–Ω—å\s+)?(\d{1,2}[.\-/]\d{1,2}(?:[.\-/]\d{2,4})?)$", text)
    if not m:
        return

    ddmm = parse_ddmm(m.group(1))
    if not ddmm:
        return

    await send_schedule(update, ddmm)


# =========================
# Main
# =========================
def main():
    load_dotenv()

    token = os.getenv("BOT_TOKEN", "").strip()
    if not token:
        raise RuntimeError("–ù–µ—Ç BOT_TOKEN...")

    # –∑–∞–ø—É—Å–∫–∞–µ–º –º–∏–Ω–∏-–≤–µ–±-—Å–µ—Ä–≤–µ—Ä, —á—Ç–æ–±—ã Render –≤–∏–¥–µ–ª –ø–æ—Ä—Ç
    keep_alive()

    app = Application.builder().token(token).build()

    # –∫–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("today", cmd_today))
    app.add_handler(CommandHandler("tomorrow", cmd_tomorrow))
    app.add_handler(CommandHandler("day", cmd_day))

    # —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞—Ç—ã
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_day))

    print("Bot started / polling")
    # –í–ê–ñ–ù–û: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ run_polling, –∏ —Ç—É—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()

# force redeploy

# fffff
